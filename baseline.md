# Предобработка
В столбце `'Кол-во комнат'` встречаются значения `[0, 1, 2, 3, 4, '5+', 'free']`. Заменим значения `"5+"` на`5` - таких значений в датасете всего 300, поэтому можно пренебречь количеством комнат в таком случае. Заменим `"free"` на `0.5` соответсвенно, чтобы было отдельное значение для свободной отделки

В столбцах `Ремонт`, `Материал стен`, `Тип жилья` не так много возможных категорий, применим к ним *one-hot encoding*

В столбце `'Станция'` очень много возможных категорий. Для его обработки применим счетчик со сглаживанием  

# Выбор метрик
Будем использовать для оценки качества моделей следующие метрики:
- R^2

  R^2 поможет в понимании, насколько дальнейшие модели лучше по сравнению с бейзлайном
- RMSE

  RMSE даст понятно интерпретируемый диапазон ошибок в той же размерности (рубли а не рубли^2)

# Обучение на вещественных признаках
Оставим только вещественные признаки, размер датасета:
- `X.shape = (77551, 8)`
- `y.shape = (77551,)`

Разделим датасет на `train`/`test` в соотношении 70/30

Применим масштабирование, обучим модели *линейной регрессию* и *Lasso* с L1-регуляризацией и посчитаем метрики
```commandline
LinearRegression()
R^2 Score: 0.7339270045171769
Mean Squared Error: 5418553.973030382

```
Среди [10, 100, 1000, 10000, 100000] подберем альфа коэффициент для регуляризации в *Lasso*, импортируем *GridSearchCV* и *ElasticNet*
```commandline
Lasso(alpha=100)
R^2 на тестовых данных: 0.7339273827056643
RMSE на тестовых данных: 5418550.122140788
```
```commandline
ElasticNet(alpha=100, l1_ratio=1, max_iter=5000)
R^2 на тестовых данных: 0.7339273827056643
RMSE на тестовых данных: 5418550.122140788
```
Видим, что по данным метрик модели, обученные на вещественных признаках, отличаются незначительно

# Обработка категориальных признаков
В датасете были даны 3 ближайшие станции для каждого объекта. После EDA было решено оставить одну ближайшую станцию, две другие удалить. Чтобы избежать переобучения применим счетчик со сглаживанием c помощью LeaveOneOutEncoder 

Преобразуем `train` и `test` выборку, применим стандартизацию на `train`

Обучим модель *Ridge* со значением `cv=10` и посчитаем метрики
```commandline
Ridge(alpha=10, max_iter=1000)
R^2 на тестовых данных: 0.7924069967628926
RMSE на тестовых данных: 4786183.663483695
```
Согласно метрикам, модель *Ridge*, обученная на вещественных и категориальных признаках, работает лучше *LinearRegression* и *Lasso* на ~8%

Также написан класс `RoomTransformer(BaseEstimator, TransformerMixin)`, реализован Pipeline для бейзлайн решения
