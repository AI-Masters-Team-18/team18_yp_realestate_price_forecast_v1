import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.base import BaseEstimator, TransformerMixin
import joblib
from telegram import Message


class TypeConverter(BaseEstimator, TransformerMixin):
    def __init__(self, columns):
        self.columns = columns

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X = X.copy()
        for col in self.columns:
            if col in X.columns:
                X[col] = X[col].astype(str)
        return X


async def train_model(message: Message):
    csv_path = os.path.join("data", "data.csv")
    model_path = os.path.join("model", "model.pkl")

    if not os.path.exists(csv_path):
        await message.reply_text(
            "‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ."
        )
        return

    if os.path.exists(model_path):
        await message.reply_text(
            "‚ö†Ô∏è –ú–æ–¥–µ–ª—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\n" "üîÑ –ü–µ—Ä–µ–æ–±—É—á–∞—é –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö..."
        )
    else:
        await message.reply_text("ü§ñ –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")

    try:
        df = pd.read_csv(csv_path)

        current_year = pd.Timestamp.now().year

        required_columns = ["–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å", "–¶–µ–Ω–∞"]
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            await message.reply_text(
                f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_columns)}"
            )
            return

        filters = []
        if "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å" in df.columns:
            filters.append(df["–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å"] <= 200)
        if "–≠—Ç–∞–∂" in df.columns:
            filters.append(df["–≠—Ç–∞–∂"] <= 50)
        if "–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏" in df.columns:
            filters.append(df["–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏"] >= (current_year - 100))
        if "–í—ã—Å–æ—Ç–∞ –ø–æ—Ç–æ–ª–∫–æ–≤" in df.columns:
            filters.append(df["–í—ã—Å–æ—Ç–∞ –ø–æ—Ç–æ–ª–∫–æ–≤"] <= 5)
        if "–¶–µ–Ω–∞" in df.columns:
            filters.append(df["–¶–µ–Ω–∞"] <= 100000000)
        if "–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏" in df.columns:
            filters.append(df["–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏"] <= 50)

        if filters:
            df_cleaned = df[np.all(filters, axis=0)]
        else:
            df_cleaned = df

        if len(df_cleaned) < 10:
            await message.reply_text(
                "‚ùå –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."
            )
            return

        X = df_cleaned.drop(columns=["–¶–µ–Ω–∞"])
        y = df_cleaned["–¶–µ–Ω–∞"]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        categorical_features = X_train.select_dtypes(
            include=["object", "category"]
        ).columns.tolist()

        preprocessor = ColumnTransformer(
            transformers=[
                (
                    "cat",
                    OneHotEncoder(
                        drop="first", handle_unknown="ignore", sparse_output=False
                    ),
                    categorical_features,
                )
            ],
            remainder="passthrough",
        )

        pipeline = Pipeline(
            [
                ("type_converter", TypeConverter(columns=categorical_features)),
                ("preprocessor", preprocessor),
                (
                    "model",
                    RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1),
                ),
            ]
        )

        pipeline.fit(X_train, y_train)

        y_pred = pipeline.predict(X_test)

        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

        if not os.path.exists("model"):
            os.makedirs("model")

        model_path = os.path.join("model", "model.pkl")
        joblib.dump(pipeline, model_path)

        report = f"""‚úÖ **–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!**
            üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:**
            ‚Ä¢ R¬≤ Score: {r2:.4f}
            ‚Ä¢ RMSE: {rmse:,.2f} —Ä—É–±.
            ‚Ä¢ MAPE: {mape:.2f}%

            üìà **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:**
            ‚Ä¢ –í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(df_cleaned):,}
            ‚Ä¢ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train):,}
            ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test):,}
            ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}

            ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!"""

        await message.reply_text(report, parse_mode="Markdown")

    except Exception as e:
        await message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
